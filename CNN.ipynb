{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3314.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2alCXo8--u6"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfiNuv5Tm3ur",
        "outputId": "60f3ecda-99e9-4c6b-a163-5d0b8c4e48e4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4ac_3Uc9tgq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchvision import transforms,datasets\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCA7pXZI-HvJ",
        "outputId": "306090c2-6dee-4a7f-e9d5-588680e46271"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrv5GsY_DVBH"
      },
      "source": [
        "num_epochs = 10\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 16\n",
        "input_size = 32*32\n",
        "hidden_layers = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJDvM3amDp0X"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((32,32)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((32,32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Dataset initialization\n",
        "data_dir = 'data' # Suppose the dataset is stored under this folder\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']} # Read train and test sets, respectively.\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,shuffle=True, num_workers=2)for x in ['train', 'test']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
        "\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "trainLoader = dataloaders['train']\n",
        "testLoader = dataloaders['test']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjyqELTNForJ"
      },
      "source": [
        "class Net2(nn.Module):\n",
        "  def __init__(self, classes):\n",
        "    super(Net2, self).__init__()\n",
        "    self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "    self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "    self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "    self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "    self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "    self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    # max pooling (kernel_size, stride)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # fully conected layers:\n",
        "    self.fc6 = nn.Linear(512, 512)\n",
        "    self.fc7 = nn.Linear(512, 100)\n",
        "    self.fc8 = nn.Linear(100, 10)\n",
        "    self.fc9 = nn.Linear(1000,10)\n",
        "  def forward(self, x, training=True):\n",
        "    x = F.relu(self.conv1_1(x))\n",
        "    x = F.relu(self.conv1_2(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2_1(x))\n",
        "    x = F.relu(self.conv2_2(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv3_1(x))\n",
        "    x = F.relu(self.conv3_2(x))\n",
        "    x = F.relu(self.conv3_3(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv4_1(x))\n",
        "    x = F.relu(self.conv4_2(x))\n",
        "    x = F.relu(self.conv4_3(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv5_1(x))\n",
        "    x = F.relu(self.conv5_2(x))\n",
        "    x = F.relu(self.conv5_3(x))\n",
        "    x = self.pool(x)\n",
        "    x = x.view(-1, 512)\n",
        "    x = F.relu(self.fc6(x))\n",
        "    x = F.dropout(x, 0.5, training=training)\n",
        "    x = F.relu(self.fc7(x))\n",
        "    x = F.dropout(x, 0.5, training=training)\n",
        "    x = self.fc8(x)\n",
        "    return x\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGH0yiYkFefo"
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(3, 256, 3),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(256, 128, 2),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(128, 64, 2),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(64, 32, 2),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(32, 8, 2),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.Conv2d(8,8,1),\n",
        "            nn.Conv2d(8,4,1),\n",
        "            nn.Conv2d(4,4,1),\n",
        "            nn.Conv2d(4,2,1),  \n",
        "            nn.Conv2d(2,2,1),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(338, 64),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(64,20),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(20, 10),\n",
        "            \n",
        "        )\n",
        "      \n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.convs(img)\n",
        "       # print(x.shape)\n",
        "        x = x.view(4,338)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCwWOOPZHRfh"
      },
      "source": [
        "def train_test(model, criterion, optimizer, scheduler, num_epochs=1500):\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss=0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in enumerate(trainLoader,0):\n",
        "      #print(type(data))\n",
        "      inputs, labels = data\n",
        "     # inputs, labels = inputs.cuda(), labels.cuda()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      running_loss+=loss.item()\n",
        "    #print(epoch) \n",
        "      \n",
        "      _, predicted = torch.max(outputs.data,1)\n",
        "      total+=labels.size(0)\n",
        "      correct+= (predicted==labels).sum().item()\n",
        "      if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "        print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss /2000 ))\n",
        "        running_loss = 0.0\n",
        "        print('Accuracy: ', 100*correct/total)\n",
        "        correct = 0\n",
        "        total = 0\n",
        "       # for i,para in enumerate(model.parameters()):\n",
        "        #  print(f'{i+1}th parameter tensor:')\n",
        "          #print(para)\n",
        "        #  print(para.grad)\n",
        "        #print()\n",
        "    #  print(\"Epoch: {}/{}. step: {}/{}, loss: {:.4f}\".format(epoch, num_epochs, i, len(trainLoader), loss.item()))\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "      for data in testLoader:\n",
        "        images, labels = data\n",
        "       # images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data,1)\n",
        "        total+=labels.size(0)\n",
        "        correct+= (predicted==labels).sum().item()\n",
        "    print('Accuracy: ', 100*correct/total)\n",
        "    \n",
        "  return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdJx349UOvME"
      },
      "source": [
        "class Net3(nn.Module):\n",
        "    \"\"\"\n",
        "    Input - 1x32x32\n",
        "    Output - 10\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Net3, self).__init__()\n",
        "        # TODO: Initialize layers\n",
        "        self.conv= nn.Sequential(\n",
        "          nn.Conv2d(3,32,3),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(32,128,2),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.MaxPool2d(3, 2),\n",
        "          nn.ReLU(),\n",
        "          nn.Flatten()\n",
        "        )\n",
        "\n",
        "\n",
        "        flatten_size = self.get_flatten_size([4,3,32,32])\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(flatten_size,32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32,10),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "    def get_flatten_size(self,shape):\n",
        "        dummy_img = torch.zeros(size=shape)\n",
        "        emb_1 = self.conv(dummy_img)\n",
        "        #conv_fc = self.nin_block(emb_1)\n",
        "        return int(np.prod(emb_1.shape[1:]))\n",
        "\n",
        "    def forward(self, img):\n",
        "\n",
        "        # TODO: Implement forward pass\n",
        "        emb_1 = self.conv(img)\n",
        "        # conv_fc = self.nin_block(emb_1)\n",
        "        y = self.fc(emb_1)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx6LnIHbjgQp"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net6(nn.Module): \n",
        "    def __init__(self):\n",
        "        super(Net6, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(9216, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(4,9216)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m9a-_UkYYyD"
      },
      "source": [
        "class Net4(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net4, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.fc = nn.Linear(in_features=16 * 16 * 24, out_features=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv1(input)\n",
        "        output = self.relu1(output)\n",
        "\n",
        "        output = self.conv2(output)\n",
        "        output = self.relu2(output)\n",
        "\n",
        "        output = self.pool(output)\n",
        "\n",
        "        output = self.conv3(output)\n",
        "        output = self.relu3(output)\n",
        "\n",
        "        output = self.conv4(output)\n",
        "        output = self.relu4(output)\n",
        "\n",
        "        output = output.view(-1, 16 * 16 * 24)\n",
        "\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlPqSLq_nwqi"
      },
      "source": [
        "class Net7(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net7, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 128, 3)\n",
        "    self.conv2 = nn.Conv2d(128,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3IhNYYeIMvp"
      },
      "source": [
        "model_ft = Net3() # Model initialization\n",
        "\n",
        "model_ft = model_ft.to(device) # Move model to cpu\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # Loss function initialization\n",
        "\n",
        "# TODO: Adjust the following hyper-parameters: learning rate, decay strategy, number of training epochs.\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001) # Optimizer initialization\n",
        "#optimizer_ft = optim.Adam(lr=0.001)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1) # Learning rate decay strategy\n",
        "\n",
        "train_test(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=1500)\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}